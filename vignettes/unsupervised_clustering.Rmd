---
title: "Perform concordance network-based clustering using PRONA"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

This vignette gives an overview of how to perform second-order,
concordance network-based unsupervised clustering to identify
communities of patients with unique symptom network patterns. For more
information on this clustering method and examples of its applications,
please see [Henry et al., Plos One,
2018](https://doi.org/10.1371/journal.pone.0191981) and [Bergsneider et
al., Neuro-Oncology Advances,
2022](https://doi.org/10.1093/noajnl/vdac188).

### 1. Load PRONA, download data, and construct a GGM

For this example, we will use the data from the introduction vignette to
construct a GGM. Please refer to the introduction vignette for more
details on where this data is from and how the network is constructed.

```{r}
library(PRONA)
reduced_df <- read.csv('../../PRONA_additional_files/test_scripts/output/reduced_data.csv', stringsAsFactors = FALSE)
ptsd_network <- construct_ggm(reduced_df, normal = FALSE)
```

```{r, fig.width=9, fig.height=6}
plot_ggm(ptsd_network, label.size = 2.5)
```

### 2. Get communities of patients with unique symptom severity/frequency patterns

To run second-order unsupervised clustering, we use the get_communities
function, which has 6 parameters:

-   data: Dataframe of symptom severities (formatted as required by
    PRONA)

-   nrows: Number of rows in the dataframe (Defaults to the number of
    rows in data, you should not change this parameter)

-   ncols: Number of columns in the dataframe (Defaults to the number of
    columns in data, you should not change this parameter)

-   detectAlgo: The community detection algorithm to use. Options
    include FG (fast greedy), IM (infomap), LP (label propagation), LE
    (leading eigen), LV (louvain), or WT (walktrap). (Default: WT)

-   simil_measure: The similarity measure to use, either 'Euclidean' or
    'ARI' (Adjusted Rand Index) (Default: ARI)

-   simplify_graphs: Boolean that indicates whether to simplify the
    graph by removing multi-edges and loops (Default: TRUE)

It returns a new dataframe that is a copy of the original symptom
severities dataframe, but with a new column representing which community
each patient belongs to.

```{r}
community_df <- get_communities(reduced_df)
```

Lets see how many patients are in each community

```{r}
table(community_df$community)
```

Next, lets plot a heatmap of symptom severities for each community using
the plot_community_heatmap function, which has four parameters:

-   df: The output of the get_communities function

-   cluster_rows: Boolean representing whether or not to cluster the
    rows (symptoms) via heirarchical clustering (Default: TRUE)

-   symptom_order: A vector of symptom names indicating the order to
    plot symptoms on the y-axis. This order will only show up if
    cluster_rows = FALSE. The default order if cluster_rows = FALSE is
    the order of column names in the dataframe (minus the ID and
    community columns)

-   colors: A vector of colors to use for plotting the heatmaps for each
    community. If there is only one color, all communities will be
    plotted in that color. If the vector denotes colors for each
    community, each community will be in a different color. If the
    length of the vector and the number of communities do not match, an
    error will be thrown. (Default: all clusters are red)

Here, "PC" stands for "Patient Community":

```{r, fig.width=7, fig.height=5}
plot_community_heatmap(community_df)
```

Here's how to plot the communities in different colors:

```{r, fig.width=7, fig.height=5}
plot_community_heatmap(community_df, colors = c('red','blue','orange'))
```

We can also visualize the symptom severities of each community using
line plots. The community_line_plot function has two parameters:

-   data: output of get_communities

-   communities: ector specifying which communities to plot. If you
    include 0 in the vector, it will plot the severity for all patients
    combined. (Default: c(0))

```{r, fig.width=7, fig.height=5}
community_line_plot(community_df, c(0,1,2))
```

We can also get a summary of each symptom in each community using the
get_community_summary function, which returns a dataframe with the mean,
median, upper bound, and lower bound of each symptom in each community.

```{r}
get_community_summary(community_df)
```

### 3. Construct networks for individual communities

We can construct GGM networks and conduct statistical assessment for
individual communities using the same pipeline as described in the
introduction and statistical assessment vignettes.

```{r}
# Get symptom data for individual communities
library(dplyr)
comm1_df <- community_df[community_df$community==1,] %>% select(-community)
comm2_df <- community_df[community_df$community==2,] %>% select(-community)
```

```{r}
comm1_ega <- construct_ggm(comm1_df, normal = FALSE)
```

```{r, fig.width=7, fig.height=5}
plot_ggm(comm1_ega, label.size = 2.5)
```

```{r}
comm2_ega <- construct_ggm(comm2_df, normal = FALSE)
```

```{r, fig.width=7, fig.height=5}
plot_ggm(comm2_ega, label.size = 2.5)
```

Because of its relatively low number of patients and low overall symptom
severity, the network for PC1 is sparse.

### 4. Perform Network Comparison Test (NCT)

We can statistically assess the differences between the two networks
using the Network Comparison Test. For details on how the Network
Comparison Test works, please see [Borkulo et al., Psychol Methods,
2022](https://pubmed.ncbi.nlm.nih.gov/35404628/). The functions in PRONA
serve as a wrapper for the functions in the [NetworkComparisonTest
package](https://github.com/cvborkulo/NetworkComparisonTest).

The run_NCT function takes 8 parameters:

-   df1: First dataframe of symptom severity/frequency data

-   df2: Second dataframe of symptom severity/frequency data

-   normal: Boolean. Whether to consider all variables normally
    distrubted. If false, conducts a non-paranormal transformation
    (Default: FALSE)

-   it: Number of bootstrapping iterations to run (Default: 2500)

-   p.adjust.methods: Character. Can be one of "holm", "hochberg",
    "hommel", "bonferroni", "BH", "BY", "fdr", or "none". To control (or
    not) for testing of multiple edges. Defaults to "none".

-   test.edges: Boolean. Whether to test differences in individual edge
    weights. (Default: TRUE)

-   test.centrality: Boolean. Whether to test differences in centrality
    measures (Default: TRUE)

-   centrality: Vector of which centrality measures to test (Default:
    c('closeness','betweenness','strength','expectedInfluence'))

```{r, results='hide'}
# Replace file path with wherever you want to save the results of NCT
nct.file <- "../../PRONA_additional_files/test_scripts/output/nct.RDS"
if (!file.exists(nct.file)){
  nct.results <- run_NCT(comm1_df, comm2_df)
  saveRDS(nct.results, nct.file)}
nct.results <- readRDS(nct.file)
```

We can plot the results of the NCT comparing global network strength and
overall network structure.

```{r, fig.width=7, fig.height=5}
library(NetworkComparisonTest)
plot_NCT(nct.results, what = "strength")
```

```{r, fig.width=7, fig.height=5}
plot_NCT(nct.results, what = "network")
```

We can also directly get the p-values from comparing each edge weight
and centrality measure

```{r}
get_NCT_pvalues(nct.results, what = "edges")
```

```{r}
get_NCT_pvalues(nct.results, what = "centralities")
```

### 5. Assess the stability of patient communities using sub-sampling analysis

To assess the stability of patient communities (aka how reliable they
are), we can use sub-sampling analysis. This technique takes random
subsamples of patients (default is subsamples of 100%, 99%, 95%, 90%,
80%, 70%, 60%, 50%, 40%, 30%, 20%, and 10% of the original dataset) and
reruns concordance network-based patient clustering on each of the
subsamples.

To perform this, we can use the cluster_subsamples function, which takes
5 parameters:

-   data: Original dataframe of symptom severities (formatted as
    required by PRONA)

-   detectAlgo: The community detection algorithm to use. It should be
    the same as what you used when you ran get_communities. (Default:
    WT)

-   simil_measure: The similarity measure to use. It should be the same
    as what you used when you ran get_communities. (Default: ARI)

-   simplify_graphs: Boolean that indicates whether to simplify the
    graph by removing multi-edges and loops. It should be the same as
    what you used when you ran get_communities. (Default: TRUE)

-   sampling_rates: A vector containing the percentages to subset the
    data by. Default is c(1, 0.99, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4,
    0.3, 0.2, 0.1). If you change this, the vector must start with 1
    (meaning the first subsample is 100% of the dataset) for downstream
    analysis to work.

```{r}
subsample_communities_df <- cluster_subsamples(reduced_df)
```

The output is a dataframe that contains the community designations for
each patient in each of the subsampling runs:

```{r}
head(subsample_communities_df, 5)
```

To see the distribution of patients across different communities in each
subsampling run, we can use the following code. It is important to note
that cluster labels do not necessarily overlap across different runs
(for example, community #2 is "subsample_communities_df\$community_1"
does not necessarily correspond to community #2 in
"subsample_communities_df\$community_0.99"). Thus, you should compare
the overall distribution of patients across different communities in
different runs, but not the number of patients under each specific
label:

```{r}
table(subsample_communities_df$community_1)
table(subsample_communities_df$community_0.99)
table(subsample_communities_df$community_0.95)
table(subsample_communities_df$community_0.9)
table(subsample_communities_df$community_0.8)
table(subsample_communities_df$community_0.7)
table(subsample_communities_df$community_0.6)
table(subsample_communities_df$community_0.5)
table(subsample_communities_df$community_0.4)
table(subsample_communities_df$community_0.3)
table(subsample_communities_df$community_0.2)
table(subsample_communities_df$community_0.1)
```

Next, to compute the stability of each of the original clusters across
all the subsampling runs, we can use the compute_cluster_stabilities and
plot_cluster_stabilities functions. These functions define "stability"
as how often data points that belong to the same cluster in the original
data are still clustered together in the subsamples (this is also known
as Prediction Strength). It is calculated by taking all the patients
that belong to one of the individual clusters, finding which communities
those patients have been grouped into in the new clustering iteration,
and dividing the size of the largest community in the new iteration by
the size of the original community.

For example, say clustering on a dataset of 1000 patients yields three
communities, one of 500 patients (community 1), one of 400 (community
2), and one of 100 (community 3). We rerun clustering on a subsample of
the data, and out of the 500 patients that originally belonged to
community 1, 400 of them still belong to the same community, 50 belong
to a different community, and 50 were randomly removed during
subsampling. The "stability" of the original community 1 for this
subsampling iteration is 400/400 = 0.8 (aka 80%).

To perform this analysis on each of the original clusters for each of
the subsampling iterations, use the following code:

```{r}
stabilities_df <- compute_cluster_stabilities(subsample_communities_df)
stabilities_df
```

To plot these results, use the plot_cluster_stabilities function:

```{r, fig.width=7, fig.height=5}
plot_cluster_stabilities(stabilities_df)
```

Finally, we can use the Adjusted Rand Index (ARI) to assess the global
stability of the community groupings across the different subsampling
iterations. This helps us understand if the overall structure of
clusters is consistent across different subsamples. We can calculate the
ARI between the original clusters (represented by
subsample_communities_df\$community_1) and each of the subsamples using
the following code:

```{r}
library(mclust)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.99)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.95)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.9)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.8)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.7)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.6)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.5)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.4)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.3)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.2)
adjustedRandIndex(subsample_communities_df$community_1, subsample_communities_df$community_0.1)
```

Although ARI is a helpful metric, it can be disproportionately skewed if
there are specific clusters that are particularly unstable, even if the
other clusters are generally stable. For this reason, we generally
prefer the above analysis of individual cluster stability over ARI
calculation because it gives you more specific information on which
clusters are reliable and which are not.
