---
title: "Introduction to the PRONA R Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

This vignette gives an overview of how the use the PRONA (Patient
Reported Outcomes Network Analysis) R package. PRONA allows users to
input their own Patient Reported Outcomes (PRO) data on symptom
occurrence/frequency/severity and use Network Analysis (NA) to identify
complex symptom concordance patterns and symptom clusters. For an
example of how our group has used NA to characterize symptom patterns in
primary brain tumor patients, please see [Bergsneider et al.,
Neuro-Oncology Advances,
2022](https://pubmed.ncbi.nlm.nih.gov/36820236/). The steps outlined in
this vignette follow the analysis pipeline described in the paper. For
more background on NA and its applications to PRO data, please refer to
the paper as well.

### 1. Load PRONA and data to analyze

First, we need to load the PRONA package and data to analyze.
Instructions on how to download the PRONA package are at
<https://github.com/bbergsneider/PRONA>. Once you have downloaded the
PRONA package, you can load it by running:

```{r setup}
library(PRONA)
```

Next, let's load a dataset to analyze. In order to be analyzed with
PRONA, data must be in a dataframe formatted with the following
specifications:

-   Each row should represent a single patient.

-   The first column must be named "ID" and contain unique
    identifications (numbers or strings) for each patient.

-   The remaining columns should represent symptoms, be named after the
    symptom, and must contain numerical values.

-   There should not be any NA values in the dataframe.

For this example, we will analyze publicly-available data on the
frequency of Post-traumatic stress disorder (PTSD) among female drug
users. To access this data and run through this tutorial yourself,
please go to the [NIH National Institute on Drug Abuse Data Share
Website](https://datashare.nida.nih.gov/study/nida-ctn-0015), click on
"CTN-0015 Data Files", fill out the required data sharing agreement, and
navigate to the file titled "qs.csv". To format the data to the proper
PRONA format, use the function format_ptsd_data(). The idea for using
this dataset as an example and the code for formatting it properly is
adapted from [Epskamp Borsboom & Fried, Behavioral Research Methods,
2018](https://pubmed.ncbi.nlm.nih.gov/28342071/).

```{r}
# Replace this filepath with where you downloaded the qs.csv file
df <- read.csv('../../PRONA_additional_files/original_data/qs.csv', stringsAsFactors = FALSE)
df <- format_ptsd_data(df)
```

PRONA requires that dataframes have no NA values in them, so we will
check if this dataframe has any NA values and then replace any NA values
with 0.

```{r}
print(any(is.na(df)))
df <- replace(df, is.na(df), 0)
```

### 2. Plot the frequency and occurrence of all symptoms

Now that we have the data loaded, let's look at the frequency and
occurrence of each symptom across all patients:

```{r, fig.width=7, fig.height=5}
plot_frequency(df)
```

```{r, fig.width=7, fig.height=5}
plot_occurrence(df)
```

### 3. Unique Variable Analysis

When working with PRO data, oftentimes some of the symptom measurements
may overlap with one another and actually capture the same underlying
latent variable. Overlapping symptoms can skew network structure,
network centrality measurements, and symptom clustering. To avoid this,
we can use Unique Variable Analysis (UVA), which is a method for
identifying redundant variables in a network by assessing their
topological overlap and consolidating them into a single underlying
variable using the Maximum Likelihood with Robust standard errors
estimate. For more details on UVA, see [Chrisensen Garrido & Golino,
Multivariate Behavioral Research,
2023](https://doi.org/10.1080/00273171.2023.2194606).

We have implemented UVA in PRONA through the calculate_wTO, plot_wTO,
and perform_uva_consolidation functions.

First, we will calculate and plot the weighted topological overlap (wTO)
for the top 20 variable pairs:

```{r}
wTO_results <- calculate_wTO(df)
```

```{r, fig.width=9, fig.height=5}
plot_wTO(wTO_results)
```

Next, we will consolidate redundant variables. The default wTO threshold
for considering variable pairs as potentially redundant is 0.25, but
other factors should also be considered when choosing this threshold
such as (1) whether the variables are at the extreme high or low ends of
severity/frequency/occurrence (variables at the extremes of
severity/frequency/occurrence can tend to exhibit false correlations
with other variables due to their limited variance) AND (2) whether the
variables have considerable conceptual overlap. In this example, the top
two variables pairs with the highest wTO
(BEING.JUMPY.OR.EASILY.STARTLED-BEING.OVER.ALERT and
UPSET.WHEN.REMINDED.OF.TRAUMA-UPSETTING.THOUGHTS.OR.IMAGES) seem to have
considerable conceptual overlap, but the third variable pair
(DISTANT.OR.CUT.OFF.FROM.PEOPLE-LESS.INTEREST.IN.ACTIVITIES) has less
conceptual overlap, so we will set a cutoff threshold of 0.275 to only
consolidate the top two variable pairs.

The parameters for the perform_uva_consolidation function are:

-   df: A dataframe representing symptom severity/frequency

-   scale: The scale on which symptom severity/frequency is measured. In
    our case, PTSD frequency is measured on a 0-3 scale, so scale = 3.
    To give another example, if your data is measured on a 0-10 scale,
    then scale = 10.

-   cut.off: The cut-off used to determine when paiwise wTO values are
    considered redundant. Must be between 0 and 1. (Default: 0.25)

-   reduce.method: Method used to reduce redundancies. Available options
    include "latent", "mean", "remove", and "sum." See Christensen et
    al. for more details. We recommend using "latent" and have set it as
    the default.

-   new.names: Vector of new names to give to consolidated variables.
    Variable pairs will be renamed in descending order of wTO. If this
    vector is not given, new variable pairs will be renamed "CV1",
    "CV2", etc\... Moreover, if reduce.method = "remove", this vector
    will not be used. (Default: NULL)

-   output_dir: The directory in which the .RDS and .csv outputs of
    perform_uva should be saved.

```{r}
uva_results <- perform_uva_consolidation(df, scale = 3, cut.off = 0.275, reduce.method = "latent", new.names = c('JUMPY.STARTLED.OVER.ALERT', 'UPSETTING.REMINDERS'), output_dir = '../../PRONA_additional_files/test_scripts/output')
```

perform_uva saves the reduced data in a .csv file titled
"reduced_data.csv". Let's read in this data and look at the new
frequency and occurrence distributions:

```{r}
reduced_df <- read.csv('../../PRONA_additional_files/test_scripts/output/reduced_data.csv', stringsAsFactors = FALSE)
```

```{r, fig.width=7, fig.height=5}
plot_frequency(reduced_df)
```

```{r, fig.width=7, fig.height=5}
plot_occurrence(reduced_df)
```

### 4. Check variable normality

Before constructing a network, all variables should be checked for
whether they are normally distributed. If they are not normally
distributed, they will need to be passed through a nonparanormal
transformation before network construction. To check if symptoms are
normally distributed, we use the Shapiro-Wilk normality test. A p-value
of \< 0.05 in the Shapiro-Wilk normality test suggests that the variable
is not normally distributed. In our dataset, we can see that all
variables are non-normally distributed:

```{r, fig.width=7, fig.height=5}
plot_density(reduced_df)
```

```{r}
check_normality(reduced_df)
```

### 5. Construct a Gaussian Graphical Model Network

Now that we are done with all the pre-processing steps, we can construct
a Gaussian Graphical Model (GGM) network for our data, assuming all
variables are non-normally distributed, and determining symptom networks
through the walktrap algorithm:

```{r}
ptsd_network <- construct_ggm(reduced_df, normal = FALSE)
```

```{r, fig.width=9, fig.height=6}
plot_ggm(ptsd_network)
```

```{r}
head(get_ggm_weights(ptsd_network))
```

### 6. Calculate network centrality measurements

Finally, we can calculate centrality and bridge centrality measurements
for the network such as strength, closeness, betweenness, and expected
influence.

```{r}
calculate_centralities(ptsd_network)
```

```{r, fig.width=7, fig.height=5}
plot_centralities(ptsd_network)
```

```{r}
calculate_bridge_centralities(ptsd_network)
```

```{r, fig.width=7, fig.height=5}
plot_bridge_centralities(ptsd_network)
```
